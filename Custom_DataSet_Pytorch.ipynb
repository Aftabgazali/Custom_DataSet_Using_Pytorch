{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "89li2imgoYsf",
        "ok0N3BASoskp",
        "TYwuQA_Xo1uc",
        "edcFNZHss-y-",
        "VI1UTvu0VQbC",
        "-6uhTb8i0fGc",
        "U9pBCBnl2nYR",
        "RJSGPERS8y_E",
        "O9exv-aK-DIG",
        "piyCbvXzW-lf",
        "RSMYvI3-fkNO",
        "qief-AQhgwu0",
        "w59WHW39kYV2",
        "mCzf1LnamLd1"
      ],
      "authorship_tag": "ABX9TyM5nGNQDm4opnTqkgzsKpoE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aftabgazali/Custom_DataSet_Using_Pytorch/blob/main/Custom_DataSet_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "89li2imgoYsf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6hX9qpXnmST"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Device Agnostic Code"
      ],
      "metadata": {
        "id": "ok0N3BASoskp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "SLN1ou-SovuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting a Subset of Food101 dataset\n"
      ],
      "metadata": {
        "id": "TYwuQA_Xo1uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# setup the path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path /\"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder exist, download it and prepare....\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} already exist\")\n",
        "else:\n",
        "  print(f\"{image_path} doesn't exist creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok= True)\n",
        "\n",
        "# Dowload the data, open the file as write binary, make the request (click on raw and copy link)\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading Pizza Steak & Sushi data\")\n",
        "  # write the contents inside the zip file\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip the data file and read the data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\" ,\"r\") as zip_ref:\n",
        "  print(\"Unzipping Pizza Steak & Sushi data....\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "9-HcA7VrpRta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data and Visualizing it"
      ],
      "metadata": {
        "id": "edcFNZHss-y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walksthrough the dir_path returning it's contents\n",
        "\n",
        "  \"\"\"\n",
        "  # Walk into each and every directories of pizza_steak_sushi\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    # print(f\"This is a dirname {dirnames} & this is the filenames {filenames}\")\n",
        "    print(f\"There are {len(dirnames)} directories & {len(filenames)} images in '{dirpath}'. \")"
      ],
      "metadata": {
        "id": "XM7PaetmtEIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "nr2sEiprtiGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the train & test dir for our ImageFolder"
      ],
      "metadata": {
        "id": "VI1UTvu0VQbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train & test paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "ip7ExAtft5sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# random.seed(42)\n",
        "\n",
        "# Get ALl the Image paths and glob them together in a list that matches a pattern: train/ any folder either sushi,steak, pizza/ pick anything that ends with .jpg\n",
        "image_path_lists = list(image_path.glob(\"train/*/*.jpg\"))\n",
        "\n",
        "# Pick a random Image from the given list\n",
        "random_image = random.choice(image_path_lists)\n",
        "\n",
        "random_image\n",
        "\n",
        "# Get the Image class from path name eg: data/pizza_steak_sushi/train/sushi/385154.jpg, the image class is sushi\n",
        "image_class = random_image.parent.stem\n",
        "image_class\n",
        "\n",
        "# Open the Image\n",
        "img = Image.open(random_image)\n",
        "\n",
        "# Print the metadata\n",
        "print(f\"Random image path: {random_image}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image Height: {img.height} width: {img.width} Size: {img.size}\")\n",
        "img"
      ],
      "metadata": {
        "id": "PH7MX_ZvudFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing using matplotlib"
      ],
      "metadata": {
        "id": "-6uhTb8i0fGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_as_array = np.asarray(img)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image Class: {image_class} | Image Shape: {img_as_array.shape} \")"
      ],
      "metadata": {
        "id": "1ZWG_gSZ0i-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image is in Numerical format\n",
        "img_as_array[0]"
      ],
      "metadata": {
        "id": "M2vsX5gj0pQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Conclusion is that the Images are not in same size Heigth is different for diff. Images"
      ],
      "metadata": {
        "id": "_2WkOPqN1OEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Data in Pytorch Tensors\n",
        "\n",
        "Before we can use our Image data with Pytorch:\n",
        "\n",
        "1. Turn your target data into tensors\n",
        "\n",
        "2. Convert the data into a `torch.utils.data.Dataset` and eventually a `torch.utils.data.DataLoader`, `Datasets` & `Batches` inorder for the model to train it easily(Faster..)\n"
      ],
      "metadata": {
        "id": "W9Kps7D51KMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Transforming the Data with `torchvision.transforms`\n"
      ],
      "metadata": {
        "id": "U9pBCBnl2nYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    # Resize our Images to 64, 64\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    # Randomly flip the image with 50% prob.\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # Turn the image into torch.tensor: Converts a PIL Image or ndarray into Tensor from a range[0,255] to [0.0,1.0]\n",
        "    transforms.ToTensor()\n",
        "    ])"
      ],
      "metadata": {
        "id": "ZcGvhxfP1EA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [0,255] --> [0.0, 1.0]\n",
        "transform(img)"
      ],
      "metadata": {
        "id": "4h2BB_q03UZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Transformed Data"
      ],
      "metadata": {
        "id": "RJSGPERS8y_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_image(image_path, transform, n=3):\n",
        "  # Select 3 random images from the image path list\n",
        "  random_image_paths = random.sample(image_path, k=n)\n",
        "\n",
        "  for image_path in random_image_paths:\n",
        "    with Image.open(image_path) as f:\n",
        "      fig, ax = plt.subplots(nrows=1,ncols=2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].set_title(f\"Original\\nSize: {f.size}\")\n",
        "      ax[0].axis(False)\n",
        "      # Apply the transformation\n",
        "      transformed_img = transform(f).permute(1,2,0) # note: we are going from [C,H,W] ---> [H,W,C] why permute? becuase matplot lib accepts image in the form [H,W,C] so we move H at first pos, W at 2nd Pos, C at 3rd Pos.\n",
        "      ax[1].imshow(transformed_img)\n",
        "      ax[1].set_title(f\"Transformed Image\\nSize: {transformed_img.shape}\")\n",
        "      ax[1].axis(False)\n",
        "\n",
        "      fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=12)"
      ],
      "metadata": {
        "id": "dGYssl3c3zY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_transformed_image(image_path=image_path_lists, transform=transform)"
      ],
      "metadata": {
        "id": "p7Fnx4vA5J79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading the Data using ImageFolder"
      ],
      "metadata": {
        "id": "O9exv-aK-DIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ImageFolder(root=train_dir, # From Training Directory Image_path/train: The ImageFolder accepts data in the form `/train/images.jpg & `/test/images.jpg\n",
        "                         transform=transform)\n",
        "\n",
        "test_data = ImageFolder(root=test_dir,\n",
        "                        transform=transform)\n",
        "\n",
        "train_data, test_data"
      ],
      "metadata": {
        "id": "H6hOg4_X-Gga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GEt Class Names\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "WdntUccM-vr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Class with Dict\n",
        "class_idx = train_data.class_to_idx\n",
        "class_idx"
      ],
      "metadata": {
        "id": "B_K2I-jA-00D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of the dataset\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "rhgbGpEb-_Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "\n",
        "\n",
        "class_names[label]"
      ],
      "metadata": {
        "id": "f6Q9o_oW_cHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorder the Image Dimensions\n",
        "img_permute = image.permute(1,2,0)\n",
        "print(f\"Original Shape: {image.shape} \")\n",
        "print(f\"Image permute Shape: {img_permute.shape}\")\n",
        "\n",
        "# Plot the Image\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(img_permute)\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "CZ6IFOZ5_yI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data into Batches"
      ],
      "metadata": {
        "id": "piyCbvXzW-lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "train_data_loader = DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
        "test_data_loader = DataLoader(dataset=test_data,batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "6KoPJxW3XFej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_loader), len(test_data_loader)"
      ],
      "metadata": {
        "id": "o8xYAhMXXiEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_data_loader))\n",
        "\n",
        "print(f\"Image shape: {img.shape}, Label {label.shape}\")"
      ],
      "metadata": {
        "id": "vx5zKoAIYVeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other forms of Transformation: Data Augmentation\n",
        "\n",
        "*Process of artificially Increase/adding diversity to your training data.*\n",
        "* It helps model, to pick out patterns from a diverese pool of images"
      ],
      "metadata": {
        "id": "lO58ncDIbH_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's look at the Trivial Augmentation"
      ],
      "metadata": {
        "id": "KjBm1oItd7Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    # Apply Trivial Augment\n",
        "    # num_bins: How Instense you want the transformation to be 31 is max.\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "itm7jiP9bK2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_lists = list(image_path.glob(\"train/*/*.jpg\"))\n",
        "image_path_lists[:5]"
      ],
      "metadata": {
        "id": "8a-9MUixeSxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_transformed_image(image_path=image_path_lists,n=3, transform=train_transform)"
      ],
      "metadata": {
        "id": "15Jp25qLea7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model_V0: TinyVGG without data augmentation\n",
        "Let's replicate the TinyVGG Model"
      ],
      "metadata": {
        "id": "0_DLywQTfLwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating transforms and loading data for Model 0"
      ],
      "metadata": {
        "id": "RSMYvI3-fkNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "SEQDwg6SfNhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_for_model_v0 = ImageFolder(root=train_dir,transform=simple_transform,target_transform=None)\n",
        "test_data_for_model_v0 = ImageFolder(root=test_dir,transform=simple_transform,target_transform=None)"
      ],
      "metadata": {
        "id": "OHcqSUWofxFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning into Batches of Images\n",
        "BATCH_SIZE = 32\n",
        "train_data_loader_model_v0 = DataLoader(dataset=train_data_for_model_v0, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_data_loader_model_v0 = DataLoader(dataset=test_data_for_model_v0, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "e_n52OQQgIfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_loader_model_v0), len(test_data_loader_model_v0)"
      ],
      "metadata": {
        "id": "eT2KBm1Jgcrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the TinyVGG Model"
      ],
      "metadata": {
        "id": "qief-AQhgwu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGGModel_V0(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture copying TinyVGG Model\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, output_shape: int, hidden_units:int):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_layer_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "\n",
        "    self.conv_layer_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*13*13, out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  # Forward Pass\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    #print(x.shape)\n",
        "    x = self.conv_layer_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.conv_layer_2(x)\n",
        "    #print(x.shape)\n",
        "    return self.classifier_layer(x)\n",
        "\n",
        "# Creating a Instance of the TinyVGG Model\n",
        "model_v0 = TinyVGGModel_V0(input_shape=3, output_shape= len(class_names), hidden_units=10)"
      ],
      "metadata": {
        "id": "WJVUANYLgvJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Random Image\n",
        "random_image = torch.randn(size=(3,64,64))\n",
        "predicted_image = model_v0(random_image.unsqueeze(0))\n",
        "# We got the value which is hidden_units*16*16"
      ],
      "metadata": {
        "id": "D2qzf5zGhEKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarly we can do:\n",
        "rand_image, rand_label = next(iter(train_data_loader_model_v0))\n",
        "predicted_image = model_v0(rand_image)"
      ],
      "metadata": {
        "id": "3qcTKaqQjkHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing the Summary for Model_V0\n",
        "Use `torchinfo` to summarize your model  "
      ],
      "metadata": {
        "id": "w59WHW39kYV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchinfo\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "# Give a Single batch of image, you can try with 32\n",
        "summary(model_v0, input_size=[1,3,64,64])\n",
        "# Output of last MaxPool Layer will be used to find the metrics to multiply in the Classifier Layer"
      ],
      "metadata": {
        "id": "II3Us_-2kbKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Model Loss & Optimizer"
      ],
      "metadata": {
        "id": "mCzf1LnamLd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(params=model_v0.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "lHxy5mwWmOhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_accuracy(y_true, y_pred):\n",
        "  acc = torch.eq(y_pred, y_true).sum().item()\n",
        "  return (acc / len(y_true))*100"
      ],
      "metadata": {
        "id": "ze4g3jkEodek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Training & Testing Step"
      ],
      "metadata": {
        "id": "b2Dq0R5DlpCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def train_step(model:torch.nn.Module, data_loader: torch.utils.data, model_loss: torch.nn.Module, model_optimizer: torch.optim, model_acc,device:torch.device=device):\n",
        "  # Training Mode:\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0,0\n",
        "  for batch, (X,y) in enumerate(data_loader):\n",
        "    # Put X & y to the device (cpu/gpu)\n",
        "    X,y = X.to(device), y.to(device)\n",
        "\n",
        "    # Forward Pass\n",
        "    y_logits = model(X)\n",
        "\n",
        "    # Calculate the Training Loss\n",
        "    loss = model_loss(y_logits, y)\n",
        "    train_loss+=loss\n",
        "\n",
        "    # Calculate the Training Accuracy\n",
        "    train_acc+=model_acc(y,y_logits.argmax(dim=1))\n",
        "\n",
        "    # Optimizer Zero grad\n",
        "    model_optimizer.zero_grad()\n",
        "\n",
        "    # Loss Backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer Step\n",
        "    model_optimizer.step()\n",
        "\n",
        "    # if batch % 2 == 0:\n",
        "    #   print(f\"Looked through {batch * len(X)} / {len(data_loader.dataset)}\")\n",
        "\n",
        "  # Update the training & accuracy & loss\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  return train_loss, train_acc\n",
        "  #print(f\"Training Loss {train_loss:.2f} | Training Accuracy {train_acc:.2f}\")"
      ],
      "metadata": {
        "id": "JLmXMYAHls_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_step(model=model_v0,no_of_epochs=5,data_loader=train_data_loader_model_v0, model_loss=model_loss, model_optimizer=model_optimizer,model_acc=model_accuracy)"
      ],
      "metadata": {
        "id": "Fi3n8mExongj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def test_step(model:torch.nn.Module, data_loader: torch.utils.data, model_loss: torch.nn.Module, model_acc,device:torch.device=device):\n",
        "    # Testing Mode:\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      test_loss, test_acc = 0,0\n",
        "      for (X_test,y_test) in (data_loader):\n",
        "        # Put X & y to the device (cpu/gpu)\n",
        "        X_test,y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "        # Forward Pass\n",
        "        y_logits = model(X_test)\n",
        "\n",
        "        # Calculate the Training Loss\n",
        "        loss = model_loss(y_logits, y_test)\n",
        "        test_loss+=loss\n",
        "\n",
        "        # Calculate the Training Accuracy\n",
        "        test_acc+=model_acc(y_test,y_logits.argmax(dim=1))\n",
        "\n",
        "      # Update the training & accuracy & loss\n",
        "      test_loss /= len(data_loader)\n",
        "      test_acc /= len(data_loader)\n",
        "\n",
        "      return test_loss, test_acc\n",
        "      #print(f\"Testing Loss {test_loss:.2f} | Testing Accuracy {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "PIVxQ6svpO7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_step(model=model_v0,data_loader=test_data_loader_model_v0, model_loss=model_loss,model_acc=model_accuracy)"
      ],
      "metadata": {
        "id": "zw-l2ocSpsFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model:torch.nn.Module, no_of_epochs:int, train_dataloader: torch.utils.data, test_dataloader:torch.utils.data, model_loss:torch.nn.Module,model_optimizer:torch.optim,model_acc,device:torch.device=device):\n",
        "  \"\"\"\n",
        "  Applies both Training & Testing Step for a Model, combines both the functions\n",
        "  \"\"\"\n",
        "  results = {\n",
        "      \"train_loss\":[],\n",
        "      \"train_acc\":[],\n",
        "      \"test_loss\":[],\n",
        "      \"test_acc\":[]\n",
        "  }\n",
        "  for epoch in tqdm(range(no_of_epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,data_loader=train_dataloader, model_loss=model_loss, model_optimizer=model_optimizer,model_acc=model_acc)\n",
        "    test_loss, test_acc = test_step(model=model,data_loader=test_dataloader, model_loss=model_loss,model_acc=model_acc)\n",
        "    results['train_loss'].append(train_loss.item())\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['test_loss'].append(test_loss.item())\n",
        "    results['test_acc'].append(test_acc)\n",
        "    print(f\"Epoch: {epoch} Training Loss {train_loss:.2f} | Training Accuracy {train_acc:.2f} | Testing Loss {test_loss:.2f} | Testing Accuracy {test_acc:.2f}\")\n",
        "\n",
        "  return {'model':model.__class__.__name__, 'Loss': f'{test_loss.item():.2f}','Accuracy': f'{test_acc:.2f}'}, results"
      ],
      "metadata": {
        "id": "rFCYTsPCqjrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0_results, model_v0_loss_acc_results_per_epoch = train_model(model_v0,5, train_data_loader_model_v0, test_data_loader_model_v0,model_loss,model_optimizer,model_accuracy)"
      ],
      "metadata": {
        "id": "igtF7N41sBbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0_results"
      ],
      "metadata": {
        "id": "Knu9cN_NwtB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0_loss_acc_results_per_epoch"
      ],
      "metadata": {
        "id": "0L24e7Cm0I6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing out the Loss & Accuracy curves for the Model"
      ],
      "metadata": {
        "id": "FDYVzhy8pMaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_v0_loss_acc_results_per_epoch.keys()"
      ],
      "metadata": {
        "id": "iWmix6hfzZX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_loss_curve(model_v0_loss_acc_results_per_epoch):\n",
        "    # Plotting the loss curves\n",
        "    train_loss = model_v0_loss_acc_results_per_epoch[\"train_loss\"]\n",
        "    test_loss = model_v0_loss_acc_results_per_epoch[\"test_loss\"]\n",
        "    epochs = range(len(train_loss))\n",
        "\n",
        "    sns.set(style=\"whitegrid\")  # Set Seaborn style\n",
        "\n",
        "    plt.figure(figsize=(8, 5))  # Set figure size\n",
        "\n",
        "    # Plot train loss\n",
        "    sns.lineplot(x=epochs, y=train_loss, marker='o', color='b', label='Train Loss')\n",
        "\n",
        "    # Plot test loss\n",
        "    sns.lineplot(x=epochs, y=test_loss, marker='o', color='g', label='Test Loss')\n",
        "\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss Curve between Train and Test\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Assuming model_v0_loss_acc_results_per_epoch is a dictionary containing \"train_loss\" and \"test_loss\" lists\n",
        "# model_v0_loss_acc_results_per_epoch = {\"train_loss\": [0.5, 0.4, 0.3], \"test_loss\": [0.6, 0.5, 0.4]}\n",
        "# print_loss_curve(model_v0_loss_acc_results_per_epoch)\n"
      ],
      "metadata": {
        "id": "lEp5SKm900R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_loss_curve(model_v0_loss_acc_results_per_epoch)"
      ],
      "metadata": {
        "id": "pm0TJOlL2gVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **On Visualizing we can deduce that, our model is overfitting as the train loss curve is going down, however, the test loss curve isn't that means it is performing pretty well with train data but isn't with test data**\n",
        "\n",
        "***One of the ways we can avoid overfitting, is to get more data, apply more augmentation, Better data, Transfer Learning, the Learning rate decay https://pytorch.org/docs/stable/optim.html, simplify your model, Loss Curve Early Stopping(Stop at the epoch when the model loss was best)***\n",
        "\n",
        "\n",
        "\n",
        "***One of the ways we can avoid underfitting, is to add more layer to your model, Tweak the Learning rate, Train for Longer, use Transfer Learning***\n"
      ],
      "metadata": {
        "id": "394ahEu64o2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Priniting out the Accuracy curves"
      ],
      "metadata": {
        "id": "J4n2BbR_25FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_acc_curve(model_v0_loss_acc_results_per_epoch):\n",
        "    # Plotting the loss curves\n",
        "    train_acc = model_v0_loss_acc_results_per_epoch[\"train_acc\"]\n",
        "    test_acc = model_v0_loss_acc_results_per_epoch[\"test_acc\"]\n",
        "    epochs = range(len(train_acc))\n",
        "\n",
        "    sns.set(style=\"whitegrid\")  # Set Seaborn style\n",
        "\n",
        "    plt.figure(figsize=(8, 5))  # Set figure size\n",
        "\n",
        "    # Plot train loss\n",
        "    sns.lineplot(x=epochs, y=train_acc, marker='o', color='b', label='Train Acc')\n",
        "\n",
        "    # Plot test loss\n",
        "    sns.lineplot(x=epochs, y=test_acc, marker='o', color='g', label='Test Acc')\n",
        "\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy Curve between Train and Test\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iGB3QzbW24uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_acc_curve(model_v0_loss_acc_results_per_epoch)"
      ],
      "metadata": {
        "id": "PPEThh3C3SVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model_V1: TinyVGG with Data Augmentation"
      ],
      "metadata": {
        "id": "Mr9b8VWsPY1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform_trivial = transforms.Compose([\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "test_transform_trivial = transforms.Compose([\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "iLu4V5ELPctg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_augmented = ImageFolder(root=train_dir, transform=train_transform_trivial)\n",
        "test_data_augmented = ImageFolder(root=test_dir, transform=test_transform_trivial)"
      ],
      "metadata": {
        "id": "XGUJBd0BPrmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning data into Batches of size 32\n",
        "BATCH_SIZE = 32\n",
        "train_data_loader_model_v1 = DataLoader(dataset=train_data_augmented, batch_size=BATCH_SIZE,shuffle=True)\n",
        "test_data_loader_model_v1 = DataLoader(dataset=test_data_augmented, batch_size=BATCH_SIZE,shuffle=False)"
      ],
      "metadata": {
        "id": "7wS40duFQiuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_loader_model_v1), len(test_data_loader_model_v1)"
      ],
      "metadata": {
        "id": "Ufh6UwHvQ6Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building TinyVGG Model"
      ],
      "metadata": {
        "id": "tyjPZkK7RAHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGGModel_V1(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture copying TinyVGG Model\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, output_shape: int, hidden_units:int):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_layer_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "\n",
        "    self.conv_layer_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*13*13, out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  # Forward Pass\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    #print(x.shape)\n",
        "    x = self.conv_layer_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.conv_layer_2(x)\n",
        "    #print(x.shape)\n",
        "    return self.classifier_layer(x)\n",
        "\n",
        "# Creating a Instance of the TinyVGG Model\n",
        "model_v1 = TinyVGGModel_V1(input_shape=3, output_shape= len(class_names), hidden_units=10)"
      ],
      "metadata": {
        "id": "X_oc-FypRCwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = nn.CrossEntropyLoss()\n",
        "model_optimizer = torch.optim.Adam(params=model_v1.parameters(), lr= 0.001)"
      ],
      "metadata": {
        "id": "wyCSGMadRYKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v1_results, model_v1_loss_acc_results_per_epoch = train_model(model_v1,5, train_data_loader_model_v1, test_data_loader_model_v1,model_loss,model_optimizer,model_accuracy)"
      ],
      "metadata": {
        "id": "HTVH475kRgFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the loss curves for Model"
      ],
      "metadata": {
        "id": "uGtiCdbRSShh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_loss_curve(model_v1_loss_acc_results_per_epoch)"
      ],
      "metadata": {
        "id": "RPkb5TU1SXsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Made Improvements with the Loss Curve, so it's much better than before. However, we are now in underfitting"
      ],
      "metadata": {
        "id": "PqE4XhvETG2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing Accuracy Curve for our Model"
      ],
      "metadata": {
        "id": "0MEgwSYIS5Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_acc_curve(model_v1_loss_acc_results_per_epoch)"
      ],
      "metadata": {
        "id": "2uZqrNKFS785"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}